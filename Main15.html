<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>MediaPipe + Fireball</title>
  <script src="https://cdn.jsdelivr.net/npm/three@0.156.1/build/three.min.js"></script>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      height: 100%;
      font-family: sans-serif;
    }

    #container {
      position: absolute;
      width: 100%;
      height: 100%;
    }

    video, canvas {
      position: absolute;
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(-1);
    }

    #infoBox {
      position: absolute;
      bottom: 10px;
      left: 10px;
      background: rgba(0, 0, 0, 0.6);
      color: white;
      padding: 10px;
      border-radius: 8px;
      font-size: 14px;
      z-index: 3;
    }
  </style>
</head>
<body>
  <div id="container">
    <video id="webcam" autoplay playsinline muted></video>
    <canvas id="output_canvas"></canvas>
    <canvas id="threeCanvas"></canvas>
    <div id="infoBox">
      <div>ðŸ§  Geste : <span id="gestureName">Aucun</span></div>
      <div>âœ‹ Mains dÃ©tectÃ©es : <span id="handsCount">0</span></div>
      <div>Statue du cube : <span id="cubeStatus">-</span></div>
      <div>Distance Index/Cube : <span id="distanceIndexCube">-</span></div>
    </div>
  </div>

  <script type="module">
    import {
      GestureRecognizer,
      FilesetResolver,
      DrawingUtils
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    const video = document.getElementById("webcam");
    const canvas = document.getElementById("output_canvas");
    const ctx = canvas.getContext("2d");
    const threeCanvas = document.getElementById("threeCanvas");

    let CubePreviousX = 0;
    let CubePreviousY = 0;
    let CubePreviousZ = 0;

    const gestureNameEl = document.getElementById("gestureName");
    const handsCountEl = document.getElementById("handsCount");
    const cubeStatus = document.getElementById("cubeStatus");
    const distanceIndexCube = document.getElementById("distanceIndexCube");

    let gestureRecognizer;
    let runningMode = "IMAGE";

    const renderer = new THREE.WebGLRenderer({ canvas: threeCanvas, alpha: true });
    const scene = new THREE.Scene();

    // Perspective camera
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.01, 100);
    camera.position.z = 1;

    const vertexShader = `
        varying vec3 vPos;
        void main() {
            vPos = position;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
    `;

    const fragmentShader = `
        precision highp float;
        varying vec3 vPos;
        uniform float iTime;
        uniform vec2 iResolution;

        #define saturate(oo) clamp(oo, 0.0, 1.0)
        #define NoiseAmplitude 0.06
        #define NoiseFrequency 4.0
        #define Animation vec3(0.0, -3.0, 0.5)
        #define Color1 vec4(1.0, 1.0, 1.0, 1.0)
        #define Color2 vec4(1.0, 0.8, 0.2, 1.0)
        #define Color3 vec4(1.0, 0.03, 0.0, 1.0)
        #define Color4 vec4(0.05, 0.02, 0.5, 1.0)

        vec3 mod289(vec3 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
        vec4 mod289(vec4 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
        vec4 permute(vec4 x) { return mod289(((x*34.0)+1.0)*x); }
        vec4 taylorInvSqrt(vec4 r){ return 1.79284291400159 - 0.85373472095314 * r; }

        float snoise(vec3 v) {
            const vec2 C = vec2(1.0/6.0, 1.0/3.0);
            const vec4 D = vec4(0.0, 0.5, 1.0, 2.0);
            vec3 i  = floor(v + dot(v, C.yyy));
            vec3 x0 = v - i + dot(i, C.xxx);
            vec3 g = step(x0.yzx, x0.xyz);
            vec3 l = 1.0 - g;
            vec3 i1 = min(g.xyz, l.zxy);
            vec3 i2 = max(g.xyz, l.zxy);
            vec3 x1 = x0 - i1 + C.xxx;
            vec3 x2 = x0 - i2 + C.yyy;
            vec3 x3 = x0 - D.yyy;
            i = mod289(i);
            vec4 p = permute(permute(permute(i.z + vec4(0.0, i1.z, i2.z, 1.0)) + i.y + vec4(0.0, i1.y, i2.y, 1.0 )) + i.x + vec4(0.0, i1.x, i2.x, 1.0 ));
            float n_ = 0.142857142857;
            vec3 ns = n_ * D.wyz - D.xzx;
            vec4 j = p - 49.0 * floor(p * ns.z * ns.z);
            vec4 x_ = floor(j * ns.z);
            vec4 y_ = floor(j - 7.0 * x_);
            vec4 x = x_ *ns.x + ns.yyyy;
            vec4 y = y_ *ns.x + ns.yyyy;
            vec4 h = 1.0 - abs(x) - abs(y);
            vec4 b0 = vec4(x.xy, y.xy);
            vec4 b1 = vec4(x.zw, y.zw);
            vec4 s0 = floor(b0)*2.0 + 1.0;
            vec4 s1 = floor(b1)*2.0 + 1.0;
            vec4 sh = -step(h, vec4(0.0));
            vec4 a0 = b0.xzyw + s0.xzyw * sh.xxyy;
            vec4 a1 = b1.xzyw + s1.xzyw * sh.zzww;
            vec3 p0 = vec3(a0.xy, h.x);
            vec3 p1 = vec3(a0.zw, h.y);
            vec3 p2 = vec3(a1.xy, h.z);
            vec3 p3 = vec3(a1.zw, h.w);
            vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2,p2), dot(p3,p3)));
            p0 *= norm.x;
            p1 *= norm.y;
            p2 *= norm.z;
            p3 *= norm.w;
            vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);
            m = m * m;
            return 42.0 * dot(m*m, vec4(dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3)));
        }

        float Turbulence(vec3 position, float minFreq, float maxFreq, float qWidth) {
            float value = 0.0;
            float cutoff = clamp(0.5/qWidth, 0.0, maxFreq);
            float fade;
            float fOut = minFreq;
            for(int i=0; i<=5; i++) {
                if(fOut >= 0.5 * cutoff) break;
                fOut *= 2.0;
                value += abs(snoise(position * fOut))/fOut;
            }
            fade = clamp(2.0 * (cutoff-fOut)/cutoff, 0.0, 1.0);
            value += fade * abs(snoise(position * fOut))/fOut;
            return 1.0 - value;
        }

        vec4 Shade(float distance) {
            float c1 = saturate(distance*10.0 + 0.5);
            float c2 = saturate(distance*5.0);
            float c3 = saturate(distance*4.0 - 0.5);
            vec4 a = mix(Color1, Color2, c1);
            vec4 b = mix(a, Color3, c2);
            return mix(b, Color4, c3);
        }

        void main() {
            float d = length(vPos);
            if(d > 0.5) discard;

            vec3 pos = vPos * 2.0;
            float displacement = Turbulence(
                pos * NoiseFrequency + Animation * iTime,
                0.1,
                1.5,
                0.03
            ) * NoiseAmplitude;

            displacement = saturate(abs(displacement));
            vec4 color = Shade(displacement);
            
            float glow = smoothstep(0.3, 0.0, d);
            gl_FragColor = vec4(color.rgb * (1.0 + glow * 2.0), 1.0 - d);
        }
    `;

    const shaderMaterial = new THREE.ShaderMaterial({
        vertexShader,
        fragmentShader,
        uniforms: {
            iTime: { value: 0 },
            iResolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) }
        },
        transparent: true,
        side: THREE.DoubleSide,
        blending: THREE.AdditiveBlending,
        depthWrite: false,
    });

    const geometry = new THREE.SphereGeometry(0.05, 64, 64);
    const cube = new THREE.Mesh(geometry, shaderMaterial);
    scene.add(cube);

    const targetMaterial = new THREE.MeshBasicMaterial({ color: 0xff0000 });
    const targetCube = new THREE.Mesh(geometry, targetMaterial);
    targetCube.position.set(0.9, 0.7, 0);
    scene.add(targetCube);

    let cubeState = "init";
    let launchVelocity = new THREE.Vector3();
    let currentCubePosition = new THREE.Vector3();
    let lastResults = null;

    const resizeCanvases = () => {
      const width = video.videoWidth;
      const height = video.videoHeight;
      [canvas, threeCanvas].forEach(c => {
        c.width = width;
        c.height = height;
        c.style.width = width + "px";
        c.style.height = height + "px";
      });
      video.style.width = width + "px";
      video.style.height = height + "px";
      renderer.setSize(width, height);
      camera.aspect = width / height;
      camera.updateProjectionMatrix();
      shaderMaterial.uniforms.iResolution.value.set(width, height);
    };

    const initGestureRecognizer = async () => {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );
      gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task"
        },
        runningMode
      });
    };

    await initGestureRecognizer();

    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
      video.srcObject = stream;
      video.onloadedmetadata = () => {
        resizeCanvases();
        runDetection();
      };
    });

    let lastVideoTime = -1;

    const runDetection = async () => {
      if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await gestureRecognizer.setOptions({ runningMode: "VIDEO" });
      }

      const drawingUtils = new DrawingUtils(ctx);
      let p5 = null;
      const predict = async () => {
        shaderMaterial.uniforms.iTime.value = performance.now() / 1000;
        
        if (video.currentTime !== lastVideoTime) {
          lastVideoTime = video.currentTime;
          const nowInMs = Date.now();
          const results = await gestureRecognizer.recognizeForVideo(video, nowInMs);

          ctx.clearRect(0, 0, canvas.width, canvas.height);

          let gesture = "Aucun";
          let numHands = results.landmarks.length;

          if (results.landmarks.length > 0) {
            const landmarks = results.landmarks[0];

            drawingUtils.drawConnectors(
              landmarks,
              GestureRecognizer.HAND_CONNECTIONS,
              { color: "#00FF00", lineWidth: 3 }
            );
            drawingUtils.drawLandmarks(landmarks, {
              color: "#FF0000",
              lineWidth: 2
            });

            const palmIndices = [0, 1, 5, 9, 13, 17];
            let sumX = 0, sumY = 0, sumZ = 0;
            palmIndices.forEach(i => {
              sumX += landmarks[i].x;
              sumY += landmarks[i].y;
              sumZ += landmarks[i].z;
            });
            const avgX = sumX / palmIndices.length;
            const avgY = sumY / palmIndices.length;
            const avgZ = sumZ / palmIndices.length;

            const baseX = avgX * 2 - 1;
            const baseY = -(avgY * 2 - 1);
            const baseZ = avgZ * 2 - 1;

            const wrist = landmarks[0];
            p5 = landmarks[5];
            const p17 = landmarks[17];

            const v1 = new THREE.Vector3(p5.x - wrist.x, p5.y - wrist.y, p5.z - wrist.z);
            const v2 = new THREE.Vector3(p17.x - wrist.x, p17.y - wrist.y, p17.z - wrist.z);
            const normal = new THREE.Vector3().crossVectors(v1, v2).normalize();

            const offset = 0.17;
            const cubeX = baseX + normal.x * offset;
            const cubeY = baseY - normal.y * offset;
            const cubeZ = -avgZ * 5;

            if (cubeState=="catching") {
              cube.position.set(cubeX, cubeY, cubeZ);
              currentCubePosition.set(cubeX, cubeY, cubeZ);

              if (p5.x < p17.x) cube.visible = false;
              else cube.visible = true;
            }
          }

          if (results.gestures.length > 0) {
            gesture = results.gestures[0][0].categoryName;

            if (gesture === "Open_Palm" && cubeState=="catching") {
              cubeState = "launching";
              cube.visible = true;
              targetCube.position.set(CubePreviousX, CubePreviousY, CubePreviousZ);
              const direction = new THREE.Vector3().subVectors(targetCube.position, currentCubePosition).normalize().negate();
              launchVelocity = direction.multiplyScalar(0.05);
            }
          }

          CubePreviousX = cube.position.x;
          CubePreviousY = cube.position.y;
          CubePreviousZ = cube.position.z;

          gestureNameEl.textContent = gesture;
          handsCountEl.textContent = numHands;
          cubeStatus.textContent = cubeState;

          if (results.landmarks.length > 0) {
            const landmarks = results.landmarks[0];
            const indexTip = landmarks[8];
            distanceIndexCube.textContent = Math.abs(cube.position.x - (indexTip.x*2-1)).toFixed(2) + "/" + Math.abs(cube.position.y - (-(indexTip.y*2-1))).toFixed(2); 

            if (Math.abs(cube.position.x - (indexTip.x*2-1)) < 0.05 && 
                Math.abs(cube.position.y - (-(indexTip.y*2-1))) < 0.05) {
              cubeState = "catching";
            }
          }
        }

        if (cubeState == "launching") {
          if (Math.abs(cube.position.x) > 2 || Math.abs(cube.position.y) > 2 || Math.abs(cube.position.z) > 2) {
            cubeState = "docking";
            cube.position.set(0.9, 0.7, 0);
          } else {
            cube.position.add(launchVelocity);
          }
        }

        renderer.render(scene, camera);
        requestAnimationFrame(predict);
      };

      predict();
    };

    window.addEventListener('resize', () => {
      shaderMaterial.uniforms.iResolution.value.set(window.innerWidth, window.innerHeight);
    });
  </script>
</body>
</html>
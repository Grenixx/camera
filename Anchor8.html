<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Cube index → personne</title>
  <script src="https://cdn.jsdelivr.net/npm/three@0.156.1/build/three.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    #container { position: relative; width: 100%; height: 100vh; }
    video, canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      object-fit: cover;
      transform: scaleX(-1);
    }
    #threeCanvas { pointer-events: none; z-index: 2; }
  </style>
</head>
<body>
  <div id="container">
    <video id="webcam" autoplay playsinline muted></video>
    <canvas id="threeCanvas"></canvas>
  </div>

  <script type="module">
    import {
      FilesetResolver,
      ObjectDetector,
      GestureRecognizer
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.mjs";

    // Éléments DOM
    const video       = document.getElementById("webcam");
    const threeCanvas = document.getElementById("threeCanvas");

    // three.js
    const renderer = new THREE.WebGLRenderer({ canvas: threeCanvas, alpha: true });
    const scene    = new THREE.Scene();
    const camera   = new THREE.PerspectiveCamera(60, 1, 0.01, 10);
    camera.position.z = 1;

    // Cube
    const cube = new THREE.Mesh(
      new THREE.BoxGeometry(0.05, 0.05, 0.05),
      new THREE.MeshNormalMaterial()
    );
    cube.visible = false;
    scene.add(cube);

    // Variables de mouvement
    let targetPos   = null;               // THREE.Vector3
    let velocity    = new THREE.Vector3();
    let isMoving    = false;
    const SPEED         = 0.2;            // unités / seconde
    const STOP_THRESHOLD = 0.02;          // arrêt proche de la cible

    // MediaPipe
    let objectDetector, gestureRecognizer;
    const offscreen = document.createElement('canvas');
    const offCtx    = offscreen.getContext('2d');
    const DETECT_INTERVAL = 300;          // ms
    let lastDetect = 0;

    // Pour calculer dt
    let prevTime = performance.now();

    // Conversion pixel → coordonnées Three.js (-1 → +1)
    function toThreeCoords(x, y) {
      return {
        x: (x / video.videoWidth) * 2 - 1,
        y: -((y / video.videoHeight) * 2 - 1)
      };
    }

    // Redimensionnement
    function resize() {
      const w = video.videoWidth;
      const h = video.videoHeight;
      if (!w || !h) return;
      [threeCanvas, video].forEach(el => {
        el.width  = w; el.height = h;
        el.style.width  = w + 'px';
        el.style.height = h + 'px';
      });
      renderer.setSize(w, h);
      camera.aspect = w/h;
      camera.updateProjectionMatrix();
      offscreen.width  = 320;
      offscreen.height = Math.round(h / w * 320);
    }

    // Initialisation
    async function init() {
      // Accès caméra arrière
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { ideal: 'environment' } }
      });
      video.srcObject = stream;
      await video.play();
      window.addEventListener('resize', resize);
      resize();

      // Chargement modèles
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );
      objectDetector = await ObjectDetector.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite",
          delegate: 'GPU'
        },
        scoreThreshold: 0.6,
        categoryAllowlist: ['person']
      });
      gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task"
        },
        runningMode: 'VIDEO'
      });

      requestAnimationFrame(loop);
    }

    // Boucle principale
    async function loop(timestamp) {
      const dt = (timestamp - prevTime) / 1000;
      prevTime = timestamp;

      // ————————————————————————
      // 1️⃣ Détection du geste chaque frame
      const g       = gestureRecognizer.recognizeForVideo(video, timestamp);
      const gesture = g.gestures?.[0]?.[0]?.categoryName;
      const tip     = g.landmarks?.[0]?.[8];

      if (gesture === "Open_Palm" && tip && !isMoving) {
        const p = toThreeCoords(tip.x * video.videoWidth, tip.y * video.videoHeight);
        cube.position.set(p.x, p.y, 0);
        cube.visible = true;
      }

      // ————————————————————————
      // 2️⃣ Détection de personne toutes les 300 ms
      if (timestamp - lastDetect > DETECT_INTERVAL) {
        lastDetect = timestamp;
        offCtx.drawImage(video, 0, 0, offscreen.width, offscreen.height);
        const result = await objectDetector.detect(offscreen);
        const person = result.detections.find(d =>
          d.categories[0].categoryName === 'person'
        );

        if (person && cube.visible && !isMoving && gesture === "Open_Palm") {
          const box = person.boundingBox;
          const cx  = (box.originX + box.width/2) * (video.videoWidth / offscreen.width);
          const cy  = (box.originY + box.height/2) * (video.videoHeight / offscreen.height);
          const t2  = toThreeCoords(cx, cy);
          targetPos = new THREE.Vector3(t2.x, t2.y, 0);

          // on calcule la vitesse normalisée
          velocity.copy(targetPos)
                  .sub(cube.position)
                  .normalize()
                  .multiplyScalar(SPEED);
          isMoving = true;
        }
      }

      // ————————————————————————
      // 3️⃣ Déplacement fluide et arrêt exact
      if (isMoving) {
        const remaining = cube.position.distanceTo(targetPos);
        const stepLen   = SPEED * dt;

        if (stepLen >= remaining) {
          // si le pas de déplacement dépasse la distance restante → position finale
          cube.position.copy(targetPos);
          isMoving = false;
          cube.visible = false;
        } else {
          // sinon, déplacement normal
          const step = velocity.clone().multiplyScalar(dt);
          cube.position.add(step);
          cube.rotation.x += dt * 2;
          cube.rotation.y += dt * 3;
        }
      }

      renderer.render(scene, camera);
      requestAnimationFrame(loop);
    }

    init();
  </script>
</body>
</html>

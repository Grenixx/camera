<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>MediaPipe + Cube + Infos</title>
  <script src="https://cdn.jsdelivr.net/npm/three@0.156.1/build/three.min.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      font-family: sans-serif;
    }

    #container {
      position: relative;
      display: inline-block;
    }

    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      transform: scaleX(-1);
    }

    #webcam {
      z-index: 0;
    }

    #output_canvas {
      z-index: 1;
    }

    #threeCanvas {
      z-index: 2;
      pointer-events: none;
    }

    #infoBox {
      position: absolute;
      top: 10px;
      left: 10px;
      background: rgba(0, 0, 0, 0.6);
      color: white;
      padding: 10px;
      border-radius: 8px;
      font-size: 14px;
      z-index: 3;
    }
  </style>
</head>
<body>
  <div id="container">
    <video id="webcam" autoplay playsinline muted></video>
    <canvas id="output_canvas"></canvas>
    <canvas id="threeCanvas"></canvas>
    <div id="infoBox">
      <div>üß† Geste : <span id="gestureName">Aucun</span></div>
      <div>‚úã Mains d√©tect√©es : <span id="handsCount">0</span></div>
      <div>‚è±Ô∏è Derni√®re d√©tection : <span id="timestamp">-</span></div>
    </div>
  </div>

  <script type="module">
    import {
      GestureRecognizer,
      FilesetResolver,
      DrawingUtils
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    const video = document.getElementById("webcam");
    const canvas = document.getElementById("output_canvas");
    const ctx = canvas.getContext("2d");
    const threeCanvas = document.getElementById("threeCanvas");

    const gestureNameEl = document.getElementById("gestureName");
    const handsCountEl = document.getElementById("handsCount");
    const timestampEl = document.getElementById("timestamp");

    let gestureRecognizer;
    let runningMode = "IMAGE";

    const renderer = new THREE.WebGLRenderer({ canvas: threeCanvas, alpha: true });
    const scene = new THREE.Scene();
    const camera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0.1, 10);
    camera.position.z = 1;

    const geometry = new THREE.BoxGeometry(0.05, 0.05, 0.05);
    const material = new THREE.MeshNormalMaterial();
    const cube = new THREE.Mesh(geometry, material);
    scene.add(cube);

    const resizeCanvases = () => {
      const width = video.videoWidth;
      const height = video.videoHeight;
      [canvas, threeCanvas].forEach(c => {
        c.width = width;
        c.height = height;
        c.style.width = width + "px";
        c.style.height = height + "px";
      });
      video.style.width = width + "px";
      video.style.height = height + "px";
      renderer.setSize(width, height);
    };

    const initGestureRecognizer = async () => {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );
      gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task"
        },
        runningMode
      });
    };

    await initGestureRecognizer();

    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
      video.srcObject = stream;
      video.onloadedmetadata = () => {
        resizeCanvases();
        runDetection();
      };
    });

    let lastVideoTime = -1;

    const runDetection = async () => {
      if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await gestureRecognizer.setOptions({ runningMode: "VIDEO" });
      }

      const drawingUtils = new DrawingUtils(ctx);

      const predict = async () => {
        if (video.currentTime !== lastVideoTime) {
          lastVideoTime = video.currentTime;
          const nowInMs = Date.now();
          const results = await gestureRecognizer.recognizeForVideo(video, nowInMs);

          ctx.clearRect(0, 0, canvas.width, canvas.height);

          let gesture = "Aucun";
          let numHands = results.landmarks.length;

          if (results.landmarks.length > 0) {
            for (const landmarks of results.landmarks) {
              drawingUtils.drawConnectors(
                landmarks,
                GestureRecognizer.HAND_CONNECTIONS,
                { color: "#00FF00", lineWidth: 3 }
              );
              drawingUtils.drawLandmarks(landmarks, {
                color: "#FF0000",
                lineWidth: 2
              });

              const palmIndices = [0, 1, 5, 9, 13, 17];
              let sumX = 0, sumY = 0, sumZ = 0;
              palmIndices.forEach(i => {
                sumX += landmarks[i].x;
                sumY += landmarks[i].y;
                sumZ += landmarks[i].z;
              });
              const avgX = sumX / palmIndices.length;
              const avgY = sumY / palmIndices.length;

              const baseX = avgX * 2 - 1;
              const baseY = -(avgY * 2 - 1);

              const wrist = landmarks[0];
              const p5 = landmarks[5];
              const p17 = landmarks[17];

              const v1 = new THREE.Vector3(p5.x - wrist.x, p5.y - wrist.y, p5.z - wrist.z);
              const v2 = new THREE.Vector3(p17.x - wrist.x, p17.y - wrist.y, p17.z - wrist.z);
              const normal = new THREE.Vector3().crossVectors(v1, v2).normalize();

              const offset = 0.17;
              const cubeX = baseX + normal.x * offset;
              const cubeY = baseY - normal.y * offset;
              const cubeZ = normal.z * offset;

              cube.position.set(cubeX, cubeY, cubeZ);
              cube.scale.set(5, 5, 5);

              const palmDir = v1.clone().normalize();
              const rotationMatrix = new THREE.Matrix4();
              rotationMatrix.lookAt(palmDir, new THREE.Vector3(0, 0, 0), new THREE.Vector3(0, 1, 0));
              cube.rotation.setFromRotationMatrix(rotationMatrix);
            }
          }

          if (results.gestures.length > 0) {
            gesture = results.gestures[0][0].categoryName;
          }

          // Affichage du cube selon le geste
          cube.visible = gesture !== "Closed_Fist";

          // Mise √† jour de l'affichage des infos
          gestureNameEl.textContent = gesture;
          handsCountEl.textContent = numHands;
          timestampEl.textContent = new Date().toLocaleTimeString();
        }

        renderer.render(scene, camera);
        requestAnimationFrame(predict);
      };

      predict();
    };
  </script>
</body>
</html>
